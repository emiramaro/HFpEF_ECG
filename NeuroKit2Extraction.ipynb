{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install neurokit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import matplotlib.pyplot as plt\n",
    "from biosppy.signals import ecg\n",
    "import neurokit2 as nk\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import concurrent\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('src'))\n",
    "# from data import load_ecgs_wfdb, load_sample\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from neurokit2 import ecg_clean\n",
    "from neurokit2 import ecg_delineate\n",
    "from neurokit2 import ecg_peaks\n",
    "from neurokit2 import ecg_phase\n",
    "from neurokit2 import ecg_quality\n",
    "\n",
    "def process_ecg(ecg_signal, sampling_rate=500, method=\"neurokit\"):\n",
    "    try:\n",
    "        ecg_cleaned = ecg_clean(ecg_signal, sampling_rate=sampling_rate, method=method)\n",
    "        \n",
    "        # R-peaks\n",
    "        instant_peaks, rpeaks, = ecg_peaks(\n",
    "            ecg_cleaned=ecg_cleaned, sampling_rate=sampling_rate, method=\"neurokit\", correct_artifacts=True\n",
    "        )\n",
    "\n",
    "        # quality = ecg_quality(ecg_cleaned, rpeaks=rpeaks['ECG_R_Peaks'], sampling_rate=sampling_rate)\n",
    "\n",
    "        # Additional info of the ecg signal\n",
    "        delineate_signal, delineate_info = ecg_delineate(\n",
    "            ecg_cleaned=ecg_cleaned, rpeaks=rpeaks, sampling_rate=sampling_rate\n",
    "        )\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "        # try:\n",
    "        #     ecg_out = ecg.ecg(signal=ecg_signal, sampling_rate=500., show=False, interactive=False)\n",
    "        #     ecg_out = ecg.correct_rpeaks(signal=ecg_signal, rpeaks=ecg_out['rpeaks'], sampling_rate=500.)\n",
    "        #     ecg_rpeaks = ecg_out['rpeaks']\n",
    "\n",
    "        #     instant_peaks, rpeaks, = ecg_peaks(\n",
    "        #         ecg_cleaned=ecg_cleaned, sampling_rate=sampling_rate, method=\"neurokit\", correct_artifacts=True\n",
    "        #     )\n",
    "\n",
    "        #     delineate_signal, delineate_info = ecg_delineate(\n",
    "        #         ecg_cleaned=ecg_cleaned, rpeaks=rpeaks, sampling_rate=sampling_rate\n",
    "        #     )\n",
    "        # except:\n",
    "        #     return None, None\n",
    "\n",
    "\n",
    "    # Rpeaks location and sampling rate in dict info\n",
    "    delineate_info = pd.DataFrame(delineate_info)\n",
    "    delineate_info['R'] = rpeaks['ECG_R_Peaks'].astype(int)\n",
    "\n",
    "    rename_dict = {\n",
    "        'ECG_P_Peaks': 'P',\n",
    "        'ECG_P_Onsets': 'P_on',\n",
    "        'ECG_P_Offsets': 'P_off',\n",
    "        'ECG_Q_Peaks': 'Q',\n",
    "        'ECG_R_Onsets': 'R_on',\n",
    "        'ECG_R_Offsets': 'R_off',\n",
    "        'ECG_S_Peaks': 'S',\n",
    "        'ECG_T_Peaks': 'T',\n",
    "        'ECG_T_Onsets': 'T_on',\n",
    "        'ECG_T_Offsets': 'T_off',\n",
    "    }\n",
    "\n",
    "    delineate_info = delineate_info.rename(columns=rename_dict)\n",
    "\n",
    "    return ecg_cleaned, delineate_info\n",
    "\n",
    "def calculate_features(wf):\n",
    "    wf = pq.read_table(wf).to_pandas()\n",
    "    wf = wf.copy()\n",
    "    # wf = wf[:, 1]\n",
    "    lead_ii = wf.iloc[:, 1]\n",
    "    signals, del_waves = process_ecg(lead_ii, sampling_rate=500, method=\"neurokit\")\n",
    "     # Check if del_waves is None before proceeding\n",
    "    \n",
    "    if del_waves is None:\n",
    "        # Create a DataFrame with one row of NaN values for each column\n",
    "        columns = ['RR_Int', 'HR', 'PR_Seg', 'PR_Int', 'ST_Seg', 'QT_Int', \n",
    "                   'QRS_Dur', 'T_Dur', 'P_Dur', 'HRV', 'SDNN', 'RMSSD', 'QRS_Amp_II', \n",
    "                   'ST_Seg_Lvl', 'Tpeak_Tend', 'P_Amp_I', 'Q_Amp_I', 'R_Amp_I', 'S_Amp_I', \n",
    "                   'T_Amp_I', 'P_Amp_II', 'Q_Amp_II', 'R_Amp_II', 'S_Amp_II', 'T_Amp_II', \n",
    "                   'P_Amp_III', 'Q_Amp_III', 'R_Amp_III', 'S_Amp_III', 'T_Amp_III', 'P_Amp_aVR', \n",
    "                   'Q_Amp_aVR', 'R_Amp_aVR', 'S_Amp_aVR', 'T_Amp_aVR', 'P_Amp_aVL', 'Q_Amp_aVL', \n",
    "                   'R_Amp_aVL', 'S_Amp_aVL', 'T_Amp_aVL', 'P_Amp_aVF', 'Q_Amp_aVF', 'R_Amp_aVF', \n",
    "                   'S_Amp_aVF', 'T_Amp_aVF', 'P_Amp_V1', 'Q_Amp_V1', 'R_Amp_V1', 'S_Amp_V1', \n",
    "                   'T_Amp_V1', 'P_Amp_V2', 'Q_Amp_V2', 'R_Amp_V2', 'S_Amp_V2', 'T_Amp_V2', \n",
    "                   'P_Amp_V3', 'Q_Amp_V3', 'R_Amp_V3', 'S_Amp_V3', 'T_Amp_V3', 'P_Amp_V4', \n",
    "                   'Q_Amp_V4', 'R_Amp_V4', 'S_Amp_V4', 'T_Amp_V4', 'P_Amp_V5', 'Q_Amp_V5', \n",
    "                   'R_Amp_V5', 'S_Amp_V5', 'T_Amp_V5', 'P_Amp_V6', 'Q_Amp_V6', 'R_Amp_V6', \n",
    "                   'S_Amp_V6', 'T_Amp_V6']\n",
    "        df_nan = pd.DataFrame([pd.NA] * len(columns)).T\n",
    "        df_nan.columns = columns\n",
    "        return df_nan\n",
    "\n",
    "    # Drop any rows that are missing values\n",
    "    del_waves = del_waves.dropna()\n",
    "\n",
    "    # Convert all values to int\n",
    "    del_waves = del_waves.astype(int)\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    sampling_rate = 500.\n",
    "\n",
    "    # Basic Intervals and Segments\n",
    "    rr_intervals = np.diff(del_waves['R']) / sampling_rate\n",
    "    features['RR_Int'] = np.mean(rr_intervals)\n",
    "    features['HR'] = 60 / features['RR_Int']\n",
    "    features['PR_Seg'] = np.mean(del_waves['R'] - del_waves['P_off']) / sampling_rate\n",
    "    features['PR_Int'] = np.mean(del_waves['R'] - del_waves['P_on']) / sampling_rate\n",
    "    features['ST_Seg'] = np.mean(del_waves['T_on'] - del_waves['S']) / sampling_rate\n",
    "    features['QT_Int'] = np.mean((del_waves['T_off'] - del_waves['Q']) / sampling_rate)\n",
    "    features['QRS_Dur'] = np.mean((del_waves['S'] - del_waves['Q']) / sampling_rate)\n",
    "    features['T_Dur'] = np.mean((del_waves['T_off'] - del_waves['T_on']) / sampling_rate)\n",
    "    features['P_Dur'] = np.mean((del_waves['P_off'] - del_waves['P_on']) / sampling_rate)\n",
    "\n",
    "    features['HRV'] = np.std(rr_intervals)\n",
    "    features['SDNN'] = np.std(rr_intervals)\n",
    "    features['RMSSD'] = np.sqrt(np.mean(np.square(np.diff(rr_intervals))))\n",
    "\n",
    "    features['QRS_Amp_II'] = np.mean(lead_ii[del_waves['R']] - lead_ii[del_waves['S']])\n",
    "    features['ST_Seg_Lvl'] = np.mean(lead_ii[del_waves['T_on']] - lead_ii[del_waves['R_off']])\n",
    "\n",
    "    features['Tpeak_Tend'] = np.mean((del_waves['T_off'] - del_waves['T']) / sampling_rate)\n",
    "\n",
    "    leads = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "\n",
    "    # Amplitude features\n",
    "    for i, lead in enumerate(leads):\n",
    "        features[f'P_Amp_{lead}'] = np.mean(wf.iloc[del_waves['P'], i])\n",
    "        features[f'Q_Amp_{lead}'] = np.mean(wf.iloc[del_waves['Q'], i])\n",
    "        features[f'R_Amp_{lead}'] = np.mean(wf.iloc[del_waves['R'], i])\n",
    "        features[f'S_Amp_{lead}'] = np.mean(wf.iloc[del_waves['S'], i])\n",
    "        features[f'T_Amp_{lead}'] = np.mean(wf.iloc[del_waves['T'], i])\n",
    "\n",
    "    # Additional Features\n",
    "    # Heart Rate Variability (HRV)\n",
    "\n",
    "    # features['R_Peak_Time'] = np.mean(del_waves['R']) / sampling_rate\n",
    "    # features['S_Depth'] = np.min(lead_ii[del_waves['S']])\n",
    "    # features['T_Peak_Time'] = np.mean(del_waves['T']) / sampling_rate\n",
    "    # features['P_Area'] = np.trapz(wf[del_waves['P_on']:del_waves['P_off']], dx=1/sampling_rate)\n",
    "    features = pd.DataFrame([features])\n",
    "    \n",
    "    return features\n",
    "\n",
    "def calculate_features_batch(ecg_minibatch):\n",
    "    \"\"\"\n",
    "    Calculate features for a batch of ECG signals.\n",
    "\n",
    "    :param ecg_minibatch: A minibatch of ECG signals with shape (minibatch, 5000, 12).\n",
    "    :return: A list of dictionaries, each containing features of a corresponding ECG signal.\n",
    "    \"\"\"\n",
    "    features_batch = []\n",
    "    for wf in ecg_minibatch:\n",
    "        try:\n",
    "            features = calculate_features(wf)\n",
    "        except:\n",
    "            features = None\n",
    "        features_batch.append(features)\n",
    "    return features_batch\n",
    "\n",
    "def split_into_batches(ecg_batch, batch_size):\n",
    "    \"\"\"\n",
    "    Split the ECG data into batches.\n",
    "\n",
    "    :param ecg_batch: A batch of ECG signals with shape (b, 5000, 12).\n",
    "    :param batch_size: Size of each batch.\n",
    "    :return: A list of batches.\n",
    "    \"\"\"\n",
    "    return [ecg_batch[i:i + batch_size] for i in range(0, len(ecg_batch), batch_size)]\n",
    "\n",
    "\n",
    "def parallel_process_ecgs(ecg_batch, batch_size=100, n_jobs=16):\n",
    "    \"\"\"\n",
    "    Parallel processing of ECG signals in batches using calculate_features_batch.\n",
    "\n",
    "    :param ecg_batch: A batch of ECG signals with shape (b, 5000, 12).\n",
    "    :param batch_size: The size of each batch for processing.\n",
    "    :param n_jobs: Number of parallel jobs to run.\n",
    "    :return: List of feature dictionaries for each ECG signal.\n",
    "    \"\"\"\n",
    "    # Split the ECG data into batches\n",
    "    batches = split_into_batches(ecg_batch, batch_size)\n",
    "    all_features = []\n",
    "\n",
    "    print(f\"Processing {len(batches)} batches of size {batch_size} with {n_jobs} jobs.\")\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=n_jobs) as executor:\n",
    "        # Submit batches to the executor\n",
    "        futures = [executor.submit(calculate_features_batch, batch) for batch in batches]\n",
    "        \n",
    "        # Collect the results as they become available\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            all_features.extend(future.result())\n",
    "    \n",
    "    return all_features\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # all, surgical, surgical_cardiac, surgical_noncardiac, icu, icu_cardiac, icu_noncardiac\n",
    "#     SAMPLE = 'surgical_noncardiac' #'surgical_noncardiac'\n",
    "#     SAMPLE_TYPE = '30d_before-day_before' #'after_admission-day_of' # 'all', '30d_before-day_before', '30d_before-day_of', 'after_admission-day_before', 'after_admission-day_of'\n",
    "\n",
    "#     sample_df = load_sample(SAMPLE, SAMPLE_TYPE)\n",
    "#     sample_df = sample_df[:10]\n",
    "#     wf_df = load_ecgs_wfdb(sample_df, batch_size=None)\n",
    "\n",
    "#     wfs = wf_df['p_signal'].to_numpy()\n",
    "#     wfs = np.stack(wfs, axis=0)\n",
    " \n",
    "#     wf = wf_df.iloc[0]['p_signal']\n",
    "#     # fig = plot_ecg(wf, additional_waveforms, additional_labels)\n",
    "#     feats = calculate_features(wf)\n",
    "\n",
    "#     # out = parallel_process_ecgs(wfs)\n",
    "\n",
    "#     # print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import getpass\n",
    "import os\n",
    "from SciServer import Authentication\n",
    "myUserName = Authentication.getKeystoneUserWithToken(Authentication.getToken()).userName\n",
    "passwd = \"westHopkins2442!\"\n",
    "\n",
    "userstring = \"username=\" + myUserName + \",workgroup=win,uid=idies,password=\" + passwd\n",
    "projectname = \"LCICM\"\n",
    "dir = \"//cloud.nas.jh.edu/sddesktop$/\" + projectname\n",
    "\n",
    "devnull = open(os.devnull, 'w')\n",
    "subprocess.run([\"sudo\", \"mkdir\", \"/home/idies/workspace/SAFE/\"], capture_output=False)\n",
    "subprocess.run([\"sudo\", \"chown\", \"idies:idies\", \"/home/idies/workspace/SAFE/\"], capture_output=False)\n",
    "try:\n",
    "    subprocess.run([\"sudo\", \"mount\", \"-t\", \"cifs\", dir, \"/home/idies/workspace/SAFE/\", \"-o\", userstring], stdout=devnull, stderr=devnull)\n",
    "except FileNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_cleaned, delineate_info = process_ecg('/home/idies/workspace/SAFE/ecg_preprocessed/13:45:00_11_01_2110_18106347')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          I     II    III    aVR    aVL    aVF     V1     V2     V3     V4  \\\n",
      "0     0.040  0.000 -0.035 -0.025 -0.015  0.035  0.005  0.020  0.005  0.005   \n",
      "1     0.030 -0.010 -0.035 -0.015 -0.020  0.030  0.005  0.015  0.005  0.005   \n",
      "2     0.020 -0.020 -0.035 -0.005 -0.025  0.025  0.005  0.015  0.005  0.005   \n",
      "3     0.020 -0.020 -0.035 -0.005 -0.025  0.025  0.005  0.015  0.005  0.005   \n",
      "4     0.020 -0.020 -0.035 -0.005 -0.025  0.025  0.005  0.020  0.015  0.005   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "4995 -0.120 -0.075  0.050  0.090 -0.010 -0.085  0.060  0.000  0.000 -0.065   \n",
      "4996 -0.130 -0.055  0.080  0.085  0.015 -0.105  0.055  0.010  0.020 -0.045   \n",
      "4997 -0.135 -0.040  0.100  0.080  0.035 -0.120  0.060  0.015  0.040 -0.025   \n",
      "4998 -0.140 -0.020  0.125  0.075  0.055 -0.135  0.055  0.020  0.045 -0.005   \n",
      "4999 -0.140  0.000  0.140  0.065  0.075 -0.140  0.045  0.020  0.045  0.005   \n",
      "\n",
      "         V5     V6  \n",
      "0    -0.035  0.000  \n",
      "1    -0.035 -0.005  \n",
      "2    -0.035 -0.005  \n",
      "3    -0.025 -0.005  \n",
      "4    -0.020  0.000  \n",
      "...     ...    ...  \n",
      "4995 -0.090 -0.170  \n",
      "4996 -0.070 -0.155  \n",
      "4997 -0.040 -0.140  \n",
      "4998 -0.020 -0.120  \n",
      "4999 -0.015 -0.100  \n",
      "\n",
      "[5000 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "wf = pq.read_table(\"/home/idies/workspace/SAFE/ecg_preprocessed/01:47:00_08_11_2110_14717666\").to_pandas()\n",
    "print(wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.040\n",
       "1       0.030\n",
       "2       0.020\n",
       "3       0.020\n",
       "4       0.020\n",
       "        ...  \n",
       "4995   -0.120\n",
       "4996   -0.130\n",
       "4997   -0.135\n",
       "4998   -0.140\n",
       "4999   -0.140\n",
       "Name: I, Length: 5000, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(delineate_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21439\n",
      "['13:45:00_11_01_2110_18106347', '15:43:00_13_01_2110_16284044', '04:02:00_17_01_2110_18780420', '08:05:00_19_01_2110_13201095', '02:02:00_22_01_2110_16006168']\n"
     ]
    }
   ],
   "source": [
    "# for HF positive patients\n",
    "import csv\n",
    "\n",
    "# import CSV w/ list of all HF positive ECG IDs\n",
    "pos_ecg_id = []\n",
    "pos_ecg_csv = open(\"/home/idies/workspace/SAFE/hf_ecg_list_id.csv\", \"r\")\n",
    "for row in pos_ecg_csv:\n",
    "    row = row.strip()\n",
    "    pos_ecg_id.append(row)\n",
    "    \n",
    "pos_ecg_id = pos_ecg_id[1:]\n",
    "print(len(set(pos_ecg_id)))\n",
    "print(pos_ecg_id[0:5])\n",
    "# 5346 total pos HF patients' ECGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RR_Int         HR    PR_Seg  PR_Int    ST_Seg    QT_Int   QRS_Dur  \\\n",
      "0  1.4288  41.993281  0.120333   0.198  0.005333  0.222333  0.137333   \n",
      "\n",
      "      T_Dur     P_Dur       HRV  ...  P_Amp_V5  Q_Amp_V5  R_Amp_V5  S_Amp_V5  \\\n",
      "0  0.079667  0.077667  0.907276  ...  0.084167  0.021667  0.211667 -0.278333   \n",
      "\n",
      "   T_Amp_V5  P_Amp_V6  Q_Amp_V6  R_Amp_V6  S_Amp_V6  T_Amp_V6  \n",
      "0 -0.006667    0.0575  0.003333  0.313333     -0.33 -0.003333  \n",
      "\n",
      "[1 rows x 75 columns]\n"
     ]
    }
   ],
   "source": [
    "df = calculate_features(\"/home/idies/workspace/SAFE/Databases/mimic-iv-ecg-parquet/12839207/23:21:00_30_08_2164_12839207.parquet\")\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Index(['RR_Int', 'HR', 'PR_Seg', 'PR_Int', 'ST_Seg', 'QT_Int', 'QRS_Dur',\n",
      "       'T_Dur', 'P_Dur', 'HRV', 'SDNN', 'RMSSD', 'QRS_Amp_II', 'ST_Seg_Lvl',\n",
      "       'Tpeak_Tend', 'P_Amp_I', 'Q_Amp_I', 'R_Amp_I', 'S_Amp_I', 'T_Amp_I',\n",
      "       'P_Amp_II', 'Q_Amp_II', 'R_Amp_II', 'S_Amp_II', 'T_Amp_II', 'P_Amp_III',\n",
      "       'Q_Amp_III', 'R_Amp_III', 'S_Amp_III', 'T_Amp_III', 'P_Amp_aVR',\n",
      "       'Q_Amp_aVR', 'R_Amp_aVR', 'S_Amp_aVR', 'T_Amp_aVR', 'P_Amp_aVL',\n",
      "       'Q_Amp_aVL', 'R_Amp_aVL', 'S_Amp_aVL', 'T_Amp_aVL', 'P_Amp_aVF',\n",
      "       'Q_Amp_aVF', 'R_Amp_aVF', 'S_Amp_aVF', 'T_Amp_aVF', 'P_Amp_V1',\n",
      "       'Q_Amp_V1', 'R_Amp_V1', 'S_Amp_V1', 'T_Amp_V1', 'P_Amp_V2', 'Q_Amp_V2',\n",
      "       'R_Amp_V2', 'S_Amp_V2', 'T_Amp_V2', 'P_Amp_V3', 'Q_Amp_V3', 'R_Amp_V3',\n",
      "       'S_Amp_V3', 'T_Amp_V3', 'P_Amp_V4', 'Q_Amp_V4', 'R_Amp_V4', 'S_Amp_V4',\n",
      "       'T_Amp_V4', 'P_Amp_V5', 'Q_Amp_V5', 'R_Amp_V5', 'S_Amp_V5', 'T_Amp_V5',\n",
      "       'P_Amp_V6', 'Q_Amp_V6', 'R_Amp_V6', 'S_Amp_V6', 'T_Amp_V6'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RR_Int', 'HR', 'PR_Seg', 'PR_Int', 'ST_Seg', 'QT_Int', 'QRS_Dur', 'T_Dur', 'P_Dur', 'HRV', 'SDNN', 'RMSSD', 'QRS_Amp_II', 'ST_Seg_Lvl', 'Tpeak_Tend', 'P_Amp_I', 'Q_Amp_I', 'R_Amp_I', 'S_Amp_I', 'T_Amp_I', 'P_Amp_II', 'Q_Amp_II', 'R_Amp_II', 'S_Amp_II', 'T_Amp_II', 'P_Amp_III', 'Q_Amp_III', 'R_Amp_III', 'S_Amp_III', 'T_Amp_III', 'P_Amp_aVR', 'Q_Amp_aVR', 'R_Amp_aVR', 'S_Amp_aVR', 'T_Amp_aVR', 'P_Amp_aVL', 'Q_Amp_aVL', 'R_Amp_aVL', 'S_Amp_aVL', 'T_Amp_aVL', 'P_Amp_aVF', 'Q_Amp_aVF', 'R_Amp_aVF', 'S_Amp_aVF', 'T_Amp_aVF', 'P_Amp_V1', 'Q_Amp_V1', 'R_Amp_V1', 'S_Amp_V1', 'T_Amp_V1', 'P_Amp_V2', 'Q_Amp_V2', 'R_Amp_V2', 'S_Amp_V2', 'T_Amp_V2', 'P_Amp_V3', 'Q_Amp_V3', 'R_Amp_V3', 'S_Amp_V3', 'T_Amp_V3', 'P_Amp_V4', 'Q_Amp_V4', 'R_Amp_V4', 'S_Amp_V4', 'T_Amp_V4', 'P_Amp_V5', 'Q_Amp_V5', 'R_Amp_V5', 'S_Amp_V5', 'T_Amp_V5', 'P_Amp_V6', 'Q_Amp_V6', 'R_Amp_V6', 'S_Amp_V6', 'T_Amp_V6']\n"
     ]
    }
   ],
   "source": [
    "print(list(df.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_name = [\"subject_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.keys():\n",
    "    cols_name.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dont run twic\n",
    "# feature_table = pd.DataFrame([[0] * 76], columns=cols_name)\n",
    "# print(feature_table)\n",
    "# feature_table.to_csv(\"/home/idies/workspace/SAFE/neurokit2_ecg_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted = pd.read_csv(\"/home/idies/workspace/SAFE/neurokit2_ecg_features.csv\", usecols=[\"subject_id\"])\n",
    "extracted = extracted[\"subject_id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21426\n",
      "09:51:00_20_07_2210_12648465\n"
     ]
    }
   ],
   "source": [
    "print(len(extracted))\n",
    "print(extracted[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['15:43:00_13_01_2110_16284044', '14:12:00_28_02_2117_16982032', '09:46:00_25_06_2128_16281507', '17:14:00_19_03_2144_16289850', '08:44:00_17_01_2151_16285428']\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "## ECG waveform not found for advance features extraction\n",
    "not_extracted = [item for item in pos_ecg_id if item not in extracted]\n",
    "print(not_extracted[0:5])\n",
    "print(len(not_extracted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_matrix(df, id):\n",
    "    reshaped = df\n",
    "    flattened = reshaped.values.flatten().tolist()\n",
    "    flattened.insert(0, id)\n",
    "\n",
    "    # Ensure that the length of 'flattened' matches the number of columns\n",
    "    assert len(flattened) == len(cols_name), f\"Mismatch: {len(flattened)} items in list, {len(cols_name)} columns expected.\"\n",
    "\n",
    "    res = pd.DataFrame([flattened], columns=cols_name)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "base_dir = '/home/idies/workspace/SAFE/ecg_preprocessed'\n",
    "curr_table_path = \"/home/idies/workspace/SAFE/neurokit2_ecg_features.csv\"\n",
    "\n",
    "# Assuming pos_ecg_id and extracted are properly defined\n",
    "# Ensure `calculate_features`, `process_ecg`, and necessary functions like `ecg_clean`, `ecg_peaks`, `ecg_delineate` are available\n",
    "\n",
    "# Initialize or load the existing table\n",
    "if os.path.exists(curr_table_path):\n",
    "    curr_table = pd.read_csv(curr_table_path)\n",
    "else:\n",
    "    curr_table = pd.DataFrame()\n",
    "\n",
    "# Process each file\n",
    "for filename in pos_ecg_id:\n",
    "    filename = filename.strip()  # Trim whitespace\n",
    "    file_path = os.path.join(base_dir, filename)  # Construct the full file path\n",
    "\n",
    "    if os.path.exists(file_path) and filename not in extracted:\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "\n",
    "        # Use `calculate_features` on the loaded ECG data\n",
    "        features = calculate_features(file_path)\n",
    "        \n",
    "        features = flatten_matrix(features, filename)\n",
    "        features2 = features.fillna(value=np.nan)\n",
    "\n",
    "        # Convert the features dict to a DataFrame row\n",
    "#         features_df = pd.DataFrame([features])\n",
    "\n",
    "        # Append the new features to the current table\n",
    "        curr_table = pd.concat([curr_table, features2], ignore_index=True)\n",
    "        \n",
    "        # Save the updated table\n",
    "        curr_table.to_csv(curr_table_path, index=False)\n",
    "        \n",
    "        # Mark this filename as processed\n",
    "        extracted.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 76)\n",
      "  subject_id RR_Int    HR PR_Seg PR_Int ST_Seg QT_Int QRS_Dur T_Dur P_Dur  \\\n",
      "0       <NA>   <NA>  <NA>   <NA>   <NA>   <NA>   <NA>    <NA>  <NA>  <NA>   \n",
      "\n",
      "   ... P_Amp_V5 Q_Amp_V5 R_Amp_V5 S_Amp_V5 T_Amp_V5 P_Amp_V6 Q_Amp_V6  \\\n",
      "0  ...     <NA>     <NA>     <NA>     <NA>     <NA>     <NA>     <NA>   \n",
      "\n",
      "  R_Amp_V6 S_Amp_V6 T_Amp_V6  \n",
      "0     <NA>     <NA>     <NA>  \n",
      "\n",
      "[1 rows x 76 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idies/miniconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/idies/miniconda3/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/idies/miniconda3/lib/python3.8/site-packages/neurokit2/signal/signal_period.py:84: NeuroKitWarning: Too few peaks detected to compute the rate. Returning empty vector.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "features = calculate_features(\"/home/idies/workspace/SAFE/ecg_preprocessed/01:47:00_08_11_2110_14717666\")\n",
    "print(features.shape)  # This should show (1, 75) if 75 features are expected plus 1 ID column\n",
    "print(features.head())  # This will show the top rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 75)\n",
      "   RR_Int  HR  PR_Seg  PR_Int  ST_Seg  QT_Int  QRS_Dur  T_Dur  P_Dur  HRV  \\\n",
      "0     NaN NaN     NaN     NaN     NaN     NaN      NaN    NaN    NaN  NaN   \n",
      "\n",
      "   ...  P_Amp_V5  Q_Amp_V5  R_Amp_V5  S_Amp_V5  T_Amp_V5  P_Amp_V6  Q_Amp_V6  \\\n",
      "0  ...       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "\n",
      "   R_Amp_V6  S_Amp_V6  T_Amp_V6  \n",
      "0       NaN       NaN       NaN  \n",
      "\n",
      "[1 rows x 75 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idies/miniconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/idies/miniconda3/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/idies/miniconda3/lib/python3.8/site-packages/numpy/core/_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/idies/miniconda3/lib/python3.8/site-packages/numpy/core/_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "/home/idies/miniconda3/lib/python3.8/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "features = calculate_features(\"/home/idies/workspace/SAFE/ecg_preprocessed/15:21:00_07_11_2110_10205294\")\n",
    "print(features.shape)  # This should show (1, 75) if 75 features are expected plus 1 ID column\n",
    "print(features.head())  # This will show the top rows of the DataFrame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
